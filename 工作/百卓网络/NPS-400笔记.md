# NPS-400概述

## 资源

*   16个集群（clusters）
*   256核
*   4096个HW线程(被操作系统视为cpu) —— 硬件线程（HW）软件线程（SW）
*   16KB CMEM & CTOP程序使用的数据cache
*   16MB IMEM — 用于查找、代码、数据、帧等的内部内存
*   DDR4高达96GB的外置内存(DDR3为48GB)
*   PMU队列有256个job队列(2x128)

## DP程序概述

当应用程序开始以数据平面模式运行时，会通过以下方式实现性能保证:

*   使用FMT代替TLB
    *   使用固定映射表将内存虚拟地址转换为相应的物理地址，因此永远不会出现TLB丢失导致停机的情况。
*   为每个HW线程(虚拟CPU)调度单个进程
    *   不需要操作系统执行上下文切换。
*   禁用定时器中断等操作系统服务
    *   因此，Linux操作系统将永远不会中断在DP模式下运行的进程，除非用户或应用程序请求。
*   将调用堆栈放置在紧密耦合的内存中
*   在关键的DP处理中避免系统调用

## Jobs

*   CTOP线程的处理任务由PMU调度
*   任务来源:
    *   传入的数据包
    *   SW事件
    *   HW事件-Timer
*   每个Job都有一个惟一的JobID
*   多达32K作业，存储在IMEM中，由PMU管理

### Job Descripto

```c
/*! job descriptor data structure */
/*! job(任务)描述符数据结构 */
struct ezdp_job_desc
{
    struct ezdp_frame_desc frame_desc;
    /**< Frame descriptor associated with the job. */
    /**< 关于job的frame(帧)描述符. */
    union
    {
        struct ezdp_job_rx_info rx_info;
        /**< Job receive info.
         * Applicable when job is received by the process or when sending or updating PMU queue. */
        /**< job接受信息.
         * 当进程接收job或发送或更新PMU队列时适用. */
        
        struct ezdp_job_tx_info tx_info;
        /**< Job transmit info.
         * Applicable when job is sent to TM. */
        /**< job传输信息.
         * 当job发送到TM时适用. */
        
        struct ezdp_job_tx_if_info ex_if_info;
        /**< Job transmit info.
         * Applicable when job is sent to IF. */
        /**< job传输信息.
         * 当job发送到IF时适用. */
    } __packed;
};
```

`struct ezdp_job_rx_info`

*   源PMU队列，源端，校验和，序列号
*   每个接口类型的特定信息:

`struct ezdp_job_rx_interface_info`

*   接待时段各类资源的拥塞程度:
    *   PMU队列，job预算，IMEM/EMEM缓冲区，
*   ICU结果，CRC结果
*   接收时间的RTC时间戳，以及它的有效性

### Frame Descripto

![2024-5-17-23-46-12.png](https://lnfeng-pic.oss-cn-wulanchabu.aliyuncs.com/byzoro-note/2024-5-17-23-46-12.png)

`struct ezdp_frame_desc`

*   Frame Type
*   Frame Len
*   Buffer Num
*   Header offset
*   第一个缓冲区描述符:类型、内存位置、ID
*   源端口 logical ID
*   服务等级 Class of service

### Free job

```c
ezdp_discard_job(ezdp_job_id * __cmem job_id_ptr, ezdp_jd * __cmem jd_ptr)
```

*   `ezdp_discard_job()`函数完成一个作业，释放所有相关的资源，包括它占用的帧和缓冲区。
*   调用`ezdp_discard_job()`表示该帧的作业处理已经结束。
*   `ezdp_discard_job()`实际上将作业传输到一个特殊的TM队列，该队列被设置为释放作业和所有相关的帧资源。

## PMU

*   PMU队列有256个job队列(2x128)
*   两个PMU，每个PMU分别有128个queue
*   每个PMU有8个应用程序调度器
*   每个调度器获得一组要使用的Cluster池。
*   每个PMU队列都配置了指定的应用程序调度程序和以下参数:
    *   Strict Priority (0-3) 严格优先级
    *   WRR Weight (0-255) WRR权重
*   应用程序队列仲裁是双层次结构。（仲裁系统：负责在两个或两个以上主体之间解决冲突的系统。）
    *   选择最高优先级队列(具有资源不足预防功能)。（电脑用语里的starvation是指资源不足，资源枯竭）
    *   根据配置的权重为队列提供WRR业务。
        ![2024-5-17-23-47-16.png](https://lnfeng-pic.oss-cn-wulanchabu.aliyuncs.com/byzoro-note/2024-5-17-23-47-16.png)

## 数据路径概述

1.  首片`frame_buffer`被写入IMEM，额外的`frame_buffer`被写入EMEM，创建一个帧描述符(`frame_desc`)来跟踪帧缓存区`frame_buffer`。
2.  网络DMA单元将有关frame的信息传递给输入分类单元（ICU）ICU根据预定义的参数对帧进行标记
3.  ICU在帧描述符中打上标签后，PMU创建`job_desc`,在该描述符中嵌入`frame_desc`,然后PMU根据ICU提供的标签将数据包排队到它的一个队列中
    ![2024-5-17-23-47-37.png](https://lnfeng-pic.oss-cn-wulanchabu.aliyuncs.com/byzoro-note/2024-5-17-23-47-37.png)
4.  job在PMU队列中排队。CTOP核心请求一个job
5.  CTOP请求到job后，PMU将`JobID`与`Job_desc`加载到CTOP核心内存中（CMEM）
6.  CTOP核心使用job描述符中嵌入的帧描述符信息来定位和加载包含帧报头的第一个帧缓冲区至CMEM，`ezframe_load_buf()`
7.  CTOP对帧进行修改，或者对job描述符中的一些信息进行更新或使用Tx的流量管理器参数（回环复制）
8.  CTOP核心回写修改后的帧块，`ezframe_store_buf()`
    ![2024-5-17-23-48-03.png](https://lnfeng-pic.oss-cn-wulanchabu.aliyuncs.com/byzoro-note/2024-5-17-23-48-03.png)
9.  CTOP核心通知PMU它已完成对作业的处理在PMU中，作业有资格进行传输。
10. 一旦作业位于队列的头部，PMU读取作业描述符，形成帧描述符并将其发送给TM
11. TM负责流量整形、QoS和发送将数据包发送到出口网络接口进行传输
12. 网络DMA引擎回读帧块并发送帧
    ![2024-5-17-23-48-24.png](https://lnfeng-pic.oss-cn-wulanchabu.aliyuncs.com/byzoro-note/2024-5-17-23-48-24.png)
13. TM可以将帧回传给PMU。为流水线模式提供流量管理。TM可以复制单帧以实现高效的多播操作

# 内存管理

> NPS支持三种不同类型的存储器:外部存储器(EMEM)、内部存储器(IMEI)和核心的本地存储器(CMEM)。下面的部分将介绍每种类型、它们的大小、典型用法和访问延迟

![2024-5-17-23-48-40.png](https://lnfeng-pic.oss-cn-wulanchabu.aliyuncs.com/byzoro-note/2024-5-17-23-48-40.png)

## EMEM

外部存储器，称为EMEM，包括NPS可用的大部分内存，最高可达48GB RAM。该内存通常用于存储大量帧数据、搜索表，并且是非性能关键型应用程序代码和数据(包括Linux操作系统)所在的地方。

顾名思义，外部存储器包含NPS外部的存储器。它由几组DRAM存储器组成。对EMEM的访问延迟从50个周期(在L2缓存中命中)到500个周期(在SDRAM访问时)不等。

EMEM可用于存储程序代码和数据以及帧缓冲区和搜索表。

通过CTOP内存管理单元和各种加速器(例如DMA、查找等)将EMEM映射到核心虚拟地址空间，软件可以使用EMEM。

为了获得最佳性能，建议在高速帧处理代码路径中通过一个加速器引擎来访问EMEM中的数据，而不是通过加载/存储操作

*   硬件支持

1.  支持DDR3(包括低电压)或DDR4存储设备
2.  高达48GB/96GB的（4x16bit/48x8bit——DDR3/DDR4）
3.  1066MHz DDR3或1333MHz DDR4时钟频率
4.  DDR3高达每秒32亿次访问，DDR4(16位设备)高达每秒39亿次访问。访问单元大小为16字节。
5.  DDR3带宽为800Gbps, DDR4带宽为1Tbps

## IMEM

内部存储器(称为IMEM)是16MB的SRAM，分布在整个芯片上，提供低延迟访问时间。这种内存通常用于存储对性能至关重要的代码和数据，以及小型搜索表和帧报头数据。

每个NPC集群集成1MB的IMEM，称为LMEM(本地内存)。NPC的IMEM由两个512KB的sub-clusters组成。

CTOP访问本地集群中的IMEM库只使用集群的内部交叉条。CTOP访问邻近集群中的IMEM库是通过EZnet分层网格交叉条路由的。

访问本地IMEM为10个周期;访问相邻集群的IMEI时的时延最长为14个周期。远程集群中IMEM的访问延迟可达30个周期。

IMEM可用于存储性能关键的程序代码和数据，以及帧缓冲区和小型搜索结构。

为了获得最佳性能，建议将关键代码和数据放在IMEM中。

*   `__imem_1_cluster_func`,函数在每个cluster的IMEI中都存放1份（16份）
*   `__imem_16_cluster_func`,函数在16MB的IMEI中只存放一份，会使不同CTOP访问周期不同
*   `__imem_1_cluster_var`、`__imem_16_cluster_var`同上，修饰变量

## CMEM

核心的本地存储器(称为CMEM)是一个16KB的SRAM库，它是每个CTOP核心的一部分。该内存用于存储与正在处理的当前帧相关的性能关键数据，例如帧标头、搜索键和结果以及临时数据。

每个ctop都有自己的CMEM。CMEM由核心的16个线程共享。但是，与IMEM不同的是，其他核心的CMEM(无论它们是否在本地集群中)都不能被除自身之外的任何CTOP访问。

在所有可用的内存类型中，CMEM的延迟最低，只有1-2个周期。

在运行期间，CMEM被划分为三个独立的区域(Figure6):线程私有区域、核心共享区域和L1数据缓存存储区域。

![2024-5-17-23-48-55.png](https://lnfeng-pic.oss-cn-wulanchabu.aliyuncs.com/byzoro-note/2024-5-17-23-48-55.png)

### 线程私有CMEM区域

CMEM的线程私有区域由核心硬件自动分割为每个线程的私有内存区域。不同线程段之间的分离和保护由硬件强制执行。在每个硬件线程上运行的软件可以使用该区域存储任务私有变量和数据结构。

### 核心共享CMEM区域

顾名思义，内核共享CMEM区域是由内核的各个硬件线程共同共享和管理的。这个区域可以用作在不同内核上运行的任务之间的共享内存，也可以用作共享堆。

与任何共享内存一样，当多个任务访问该内存时，应该小心，通过使用同步技术(如锁)来确保面对伪并发访问时数据结构的一致性。

### L1 Data Cache区域

CMEM内存的一部分被配置为用作核心L1数据缓存的后备存储。一旦配置好，这个内存就由核心硬件在内部使用，对程序员是不可见的。

### L1 Instruction Cache

L1指令缓存的大小为8 KB，与32字节的缓存线进行双向关联。NPS每个内核都有一个指令缓存，该缓存在该内核中的所有线程之间共享

##

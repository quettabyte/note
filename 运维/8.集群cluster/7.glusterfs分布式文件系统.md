## glusterfs分布式文件系统

### 一、分布式文件系统 

```
适用于海量数据的存储
部署分布式文件系统的应用:
	glusterfs、hadoop(hdfs)、ceph、mosefs
```

#### 1、glusterfs特性

```
1、开源的
2、容量达到PB级、服务器的最多达到千台
3、提升数据读写速度、高用性
4、无元数据的架构, 采用弹性hash定位数据
5、可以廉价的pc server上构建
6、支持多种挂载的方式
```

#### 2、glustefs工作流程

![image-20210311094206636](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210311094206636.png)

```
brick: 由集群中的服务器提供的真实存储空间; 设备的挂载点
volume: 虚拟存储空间, 呈现给业务服务器，业务服务器通过挂载的方式进行数据读写
```



### 二、部署gluster集群

#### 1、关闭防火墙、SELinux、时间同步

#### 2、配置免密SSH

```
[root@node01 ~]# ssh-keygen -t rsa
[root@node01 ~]# mv /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys
[root@node01 ~]# scp -r /root/.ssh/ root@192.168.140.11:/root/
[root@node01 ~]# scp -r /root/.ssh/ root@192.168.140.12:/root/
[root@node01 ~]# scp -r /root/.ssh/ root@192.168.140.13:/root/
[root@node01 ~]# scp -r /root/.ssh/ root@192.168.140.14:/oot/

[root@node01 ~]# for i in 10 11 12 13 14
> do
> ssh root@192.168.140.$i hostname
> ssh root@192.168.140.$i date
> done

```

#### 3、添加主机名解析 

```
[root@node01 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.140.10	node01.linux.com
192.168.140.11	node02.linux.com
192.168.140.12	node03.linux.com
192.168.140.13	node04.linux.com
192.168.140.14	node05.linux.com

[root@node01 ~]# for i in 11 12 13 14
> do
> rsync -av /etc/hosts root@192.168.140.$i:/etc/hosts
> done

```

#### 4、配置glusterfs的软件仓库 

```
[root@node01 ~]# cat /etc/yum.repos.d/gluster.repo
[gluster]
name=gluster
baseurl=http://mirrors.163.com/centos/7.9.2009/storage/x86_64/gluster-6/
enabled=1
gpgcheck=0

[root@node01 ~]# for i in 11 12 13 14
> do
> rsync -av /etc/yum.repos.d/gluster.repo root@192.168.140.$i:/etc/yum.repos.d/gluster.repo 
> done

```

#### 5、安装glusterfs软件

```
[root@node01 ~]# for i in 10 11 12 13 14
> do
> ssh root@192.168.140.$i yum install -y glusterfs-server glusterfs-fuse glusterfs
> done 

```

#### 6、启动glusterd服务 

```
[root@node01 ~]# for i in 10 11 12 13 14
> do
> ssh root@192.168.140.$i systemctl start glusterd
> ssh root@192.168.140.$i systemctl enable glusterd
> ssh root@192.168.140.$i hostname
> ssh root@192.168.140.$i systemctl is-active glusterd
> done

```

#### 7、创建gluster集群

```
[root@node01 ~]# gluster peer probe node02.linux.com
peer probe: success. 
[root@node01 ~]# gluster peer probe node03.linux.com
peer probe: success. 
[root@node01 ~]# gluster peer probe node04.linux.com
peer probe: success. 
[root@node01 ~]# gluster peer probe node05.linux.com
peer probe: success.
```

```
[root@node01 ~]# gluster peer status
Number of Peers: 4

Hostname: node02.linux.com
Uuid: e2fc0c50-c5f0-4948-8212-2e1cfe9266c3
State: Peer in Cluster (Connected)

Hostname: node03.linux.com
Uuid: 1e244ade-dac5-4d55-b862-ba57c300cf6c
State: Peer in Cluster (Connected)

Hostname: node04.linux.com
Uuid: a8723e2d-d36e-4324-b736-8c9f66b8b11b
State: Peer in Cluster (Connected)

Hostname: node05.linux.com
Uuid: 48a41516-fb50-4083-a79a-91df9afea3f2
State: Peer in Cluster (Connected)
[root@node01 ~]# 

```



### 三、创建卷volume

#### 1、分布式卷  distribute 

```
特性: 以单个文件为单位，分散存储到不同的brick上
适用于大量的小文件，增加数据读写速度
分布式卷容量===所有brick之和
无brick数量的限制
```

```
[root@node01 ~]# gluster volume create dis_volume \
> node01.linux.com:/data1/br1 \
> node02.linux.com:/data1/br1 
volume create: dis_volume: success: please start the volume to access data

[root@node01 ~]# gluster volume start dis_volume 
volume start: dis_volume: success

[root@node01 ~]# gluster volume info dis_volume 
 
Volume Name: dis_volume
Type: Distribute
Volume ID: 66c3bb68-5dc7-4de4-b113-3a977b4aa3d5
Status: Started
Snapshot Count: 0
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: node01.linux.com:/data1/br1
Brick2: node02.linux.com:/data1/br1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
```

##### 客户端挂载使用卷

```
[root@node01 ~]# rsync -av /etc/yum.repos.d/gluster.repo root@192.168.140.15:/etc/yum.repos.d/
[root@client ~]# yum install -y glusterfs glusterfs-fuse

[root@client ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.140.10	node01.linux.com
192.168.140.11	node02.linux.com
192.168.140.12	node03.linux.com
192.168.140.13	node04.linux.com
192.168.140.14	node05.linux.com

```

```
[root@client ~]# mount -t glusterfs node02.linux.com:/dis_volume /test/
[root@client ~]# df -hT
node02.linux.com:/dis_volume fuse.glusterfs  3.9G   52M  3.6G   2% /test

开机自动挂载: 

node02.linux.com:/dis_volume    /test   glusterfs       defaults,_netdev        0 0

```



#### 2、复制卷   replicate

```
文件被复制为多份，保存到brick上
提高文件的可用性

replica指定的复制数要与brick数量一致
```

![image-20210311111834592](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210311111834592.png)



```
[root@node01 ~]# gluster volume create replica_volume replica 3 \
> node01.linux.com:/data2/br1 \
> node02.linux.com:/data2/br1 \
> node03.linux.com:/data2/br1 
volume create: replica_volume: success: please start the volume to access data

[root@node01 ~]# gluster volume start replica_volume 
volume start: replica_volume: success

[root@node01 ~]# gluster volume info replica_volume
 
Volume Name: replica_volume
Type: Replicate
Volume ID: 9513e71c-0d64-434b-9f86-3b9cdc327b42
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: node01.linux.com:/data2/br1
Brick2: node02.linux.com:/data2/br1
Brick3: node03.linux.com:/data2/br1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off

```



#### 3、分布复制卷  distribute-replicate

```
适用于保存小文件，提升文件可用性
brick数量为replica参数的整倍数
```

![image-20210311113100303](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20210311113100303.png)

```
[root@node01 ~]# gluster volume create dis_replica_volume replica 2 node01.linux.com:/data3/br1 node02.linux.com:/data3/br1 node03.linux.com:/data3/br1 node04.linux.com:/data3/br1 
Replica 2 volumes are prone to split-brain. Use Arbiter or Replica 3 to avoid this. See: http://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/.
Do you still want to continue?
 (y/n) y
volume create: dis_replica_volume: success: please start the volume to access data

[root@node01 ~]# gluster volume start dis_replica_volume 
volume start: dis_replica_volume: success

[root@node01 ~]# gluster volume info dis_replica_volume
 
Volume Name: dis_replica_volume
Type: Distributed-Replicate
Volume ID: 8537502f-a03c-4f0b-b88b-db3d72136dd8
Status: Started
Snapshot Count: 0
Number of Bricks: 2 x 2 = 4
Transport-type: tcp
Bricks:
Brick1: node01.linux.com:/data3/br1
Brick2: node02.linux.com:/data3/br1
Brick3: node03.linux.com:/data3/br1
Brick4: node04.linux.com:/data3/br1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on
performance.client-io-threads: off

```



#### 4、分散卷 disperse 

```
单个文件被拆分成多份，分散存储在不同的brick上，会有指定数量的brick用于保存数据的校验码
提升数据的读写速度、可靠性
适用于大文件存储


disperse： 用于指定brick数量
redundany: 指定用于保存校验码的brick数量，不指定的话，gluster集群会自动选定brick数量用于保存校验码
```

```
[root@node01 ~]# gluster volume create perse_volume disperse 4 \
> node01.linux.com:/data4/br1 \
> node02.linux.com:/data4/br1 \
> node03.linux.com:/data4/br1 \
> node04.linux.com:/data4/br1 
There isn't an optimal redundancy value for this configuration. Do you want to create the volume with redundancy 1 ? (y/n) y
volume create: perse_volume: success: please start the volume to access data

[root@node01 ~]# gluster volume start perse_volume 

[root@node01 ~]# gluster volume info perse_volume 
 
Volume Name: perse_volume
Type: Disperse
Volume ID: 57d44e86-cf3a-4e18-820a-28e14797d585
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x (3 + 1) = 4
Transport-type: tcp
Bricks:
Brick1: node01.linux.com:/data4/br1
Brick2: node02.linux.com:/data4/br1
Brick3: node03.linux.com:/data4/br1
Brick4: node04.linux.com:/data4/br1
Options Reconfigured:
transport.address-family: inet
nfs.disable: on

```



### 四、卷管理操作

#### 1、扩展卷  Expanding Volume

```
注意：
	扩展分布复制卷时，添加的brick的数量需要为replica参数的整倍数
	扩展分布分散卷时，添加的brick的数量需要为disperse参数的整倍数 
```

##### 示例: 扩展分布式卷

##### 1) 扩展卷

```
[root@node01 ~]# gluster volume add-brick dis_volume node03.linux.com:/data1/br1
volume add-brick: success

[root@node01 ~]# gluster volume info dis_volume 
 
Volume Name: dis_volume
Type: Distribute
Volume ID: 66c3bb68-5dc7-4de4-b113-3a977b4aa3d5
Status: Started
Snapshot Count: 0
Number of Bricks: 3
Transport-type: tcp
Bricks:
Brick1: node01.linux.com:/data1/br1
Brick2: node02.linux.com:/data1/br1
Brick3: node03.linux.com:/data1/br1

```

##### 2) 重分布卷，确保文件可以被分散保存到新brick上

```
[root@node01 ~]# gluster volume rebalance dis_volume start
volume rebalance: dis_volume: success: Rebalance on dis_volume has been started successfully. Use rebalance status command to check status of the rebalance process.
ID: f08e2e7c-337f-4895-b3ec-e2a86376d08e

[root@node01 ~]# gluster volume rebalance dis_volume status
                                    Node Rebalanced-files          size       scanned      failures       skipped               status  run time in h:m:s
                               ---------      -----------   -----------   -----------   -----------   -----------         ------------     --------------
                        node02.linux.com                4        0Bytes            12             0             0            completed        0:00:00
                        node03.linux.com                0        0Bytes             7             0             0            completed        0:00:00
                               localhost                7        0Bytes            24             0             0            completed        0:00:00
volume rebalance: dis_volume: success

```



#### 2、缩减卷  shrinking volume

```
注意：
	缩减分布复制卷、分布式分散卷时，缩减的brick数量要为replica参数的整倍数
```

##### 示例：缩减分布式卷 

##### 1) 迁移数据 

```
[root@node01 ~]# gluster volume remove-brick dis_volume node03.linux.com:/data1/br1 start
```

##### 2) 查看数据迁移的状态，确保为competed完成 的状态 

```
[root@node01 ~]# gluster volume remove-brick dis_volume node03.linux.com:/data1/br1 status
                                    Node Rebalanced-files          size       scanned      failures       skipped               status  run time in h:m:s
                               ---------      -----------   -----------   -----------   -----------   -----------         ------------     --------------
                        node03.linux.com               11        0Bytes            11             0             0            completed        0:00:00

```

##### 3) 删除brick

```
[root@node01 ~]# gluster volume remove-brick dis_volume node03.linux.com:/data1/br1 commit
```

##### 4）查看卷的状态 

```
[root@node01 ~]# gluster volume info dis_volume 
 
Volume Name: dis_volume
Type: Distribute
Volume ID: 66c3bb68-5dc7-4de4-b113-3a977b4aa3d5
Status: Started
Snapshot Count: 0
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: node01.linux.com:/data1/br1
Brick2: node02.linux.com:/data1/br1
Options Reconfigured:
performance.client-io-threads: on
nfs.disable: on
transport.address-family: inet

```



#### 3、替换故障卷   replace faulty volume

```
replace-brick命令

	注意: 该命令只适用于分布式复制卷、复制卷 
```

##### 其他类型卷的替换

```
1、添加新brick[不需要手动执行rebalance]
2、删除旧brick, 确认数据迁移完毕，再commit删除
```



##### 示例: 替换复制卷中的brick

```
[root@node01 ~]# gluster volume replace-brick replica_volume node03.linux.com:/data2/br1 node04.linux.com:/data2/br1 commit force 
volume replace-brick: success: replace-brick commit force operation successful


[root@node01 ~]# gluster volume info replica_volume 

Volume Name: replica_volume
Type: Replicate
Volume ID: 9513e71c-0d64-434b-9f86-3b9cdc327b42
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: node01.linux.com:/data2/br1
Brick2: node02.linux.com:/data2/br1
Brick3: node04.linux.com:/data2/br1
```



#### 4、设置卷的参数

```
格式:

# gluster volume set <卷名称>  <参数名称>  <值>
```

```
1、基于客户端地址进行访问控制
    auth.allow
    auth.reject
    
2、performance.write-behind-window-size
设置写缓冲区大小，默认1M

3、performance.io-thread-count
设置卷的IO线程数量 1--64

4、performance.cache-size
设置卷的缓存大小

5、performance.cache-max-file-size
设置缓存的最大文件大小

6、performance.cache-min-file-size
设置缓存的最小文件大小

7、performance.cache-refresh-timeout
设置缓存区的刷新时间间隔, 单位秒
```



